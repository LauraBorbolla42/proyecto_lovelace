%
% Contenido estático de página de inicio.
% Reporte técnico.
% Proyecto Lovelace.
%

\subsection{¿Qué es la tokenización?}

\subsubsection{Primero, ¿qué es un token?}

Antes de definir la \textit{tokenización}, es menester definir lo que es
un token: normalmente, se le conoce como un valor representativo de otro
valor; el concepto de token es ampliamente utilizado en otros contextos,
y, dependiendo de este, varían sus características. En la criptografía
(que es el contexto en el que se encuentra este servicio), este
\textit{valor representativo} no debe tener una relación directa con el
valor original; de hecho, que un adversario posea un token no representa
peligro alguno, pues no es posible, sin los mecanismos de
detokenización, regresar al valor original. Por lo tanto, un token puede
ser utilizado para proteger información confidencial.

\subsubsection{Sobre la tokenización}

Con esta definición de un token, se puede definir a la tokenización como
el proceso en el que se obtiene el valor sustituto. Este paradigma de
sustituir datos sensibles por datos representativos (y sin valor) es
relativamente nuevo, pero muy útil al momento de proteger la
información, pues permite concentrar toda la información valiosa en un
solo lugar y dejar de preocuparse por protegerla en todos lados (en vez
de vigilar un castillo, se vigila una habitación).

La operación inversa, es decir dado un token, obtener el PAN (número de
cuenta, por sus siglas en inglés) que le corresponde, es llamada
\textit{detokenización}.

\subsection{¿Por qué utilizar un servicio de tokenización?}

Desde que el comercio eletrónico comenzó a popularizarse, los fraudes
relacionados con las tarjetas bancarias y el comercio en línea
crecieron, pues los sitios bancarios y de comercio no estaban
preparados para la demanda y las amenazas de seguridad a las que
comenzaron a enfrentarse. Por lo tanto, en 2004, fue publicado por
primera vez un estándar (PCI DSS, respaldado por compañías como VISA y
MasterCard) donde se dan las guías de seguridad que deberían seguir
todos aquellos que traten con datos de tarjetas o realicen transacciones
bancarias.

Aunque este estándar no es obligatorio para aquellas entidades que
realicen menos de 20 000 transacciones en un año; es extremadamente
recomendable que sigan la guía para mantener segura la información y
transacciones.  Empero, satisfacer completamente el estándar es una
verdadera proeza, cuenta con más de 200 requerimientos para asegurar la
robustez y seguridad del sistema que trata con los datos y pagos con
tarjetas bancarias.

Es aquí donde entran los servicios de tokenización, pues se encargan de
cumplir con todos los requerimientos y quitarle esa pesada carga para
que pueda enfocarse en sus actividades sin preocuparse por el estándar y
sus implementaciones. Obviamente, es muy importante saber cómo es que
servicio de tokenización está obteniendo los tokens, pues no basta con
asegurar que son seguros; los servicios deben indicar (y hacer públicos)
los algoritmos que utilizan para generar los tokens. Por lo tanto, que
un servicio clame que tiene la mejor manera para generar tokens, pero no
especifique cómo es que los está obteniendo (o que lo haga de manera
vaga, por ejemplo, asegurando que sus tokens son obtenidos
aleatoriamente sin dar más detalles), es inadmisible, pues un buen
algoritmo tokenizador no depende en absoluto de ser mantenido en
secreto.

\subsection{¿Por qué utilizar ESTE servicio de tokenización?}

A diferencia de otros competidores, nosotros somos transparentes
respecto a la manera en la que se generan los tokens (¡nuestras
implementaciones son públicas!); actualmente, hay cinco algoritmos
distintos para obtener tokens y usted puede decidir, para cada token, el
algoritmo que será utilizado: un poco más adelante hay una sección que
explica brevemente cada algoritmo.
