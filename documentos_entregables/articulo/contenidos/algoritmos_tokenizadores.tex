%
% Sección de algoritmos tokenizadores.
% Artículo.
% Proyecto Lovelace.
%

\section{Algoritmos tokenizadores}
\label{sec:algoritmos}

Como el enfoque de este artículo es ver a la generación de tokens como un
servicio (Figura \ref{figura:arquitectura_tokenizacion}), la interfaz para los
procesos de tokenización y detokenización, desde el punto de vista de los
usuarios del servicio, es sumamente simple: el proceso para generar tokens es
una función $ E: \mathcal{X} \rightarrow \mathcal{Y} $ y el proceso para
regresar a los números de tarjeta es simplemente la función inversa $ D:
\mathcal{Y} \rightarrow \mathcal{X} $, en donde $ \mathcal{X} $ y $ \mathcal{Y}
$ son los espacios de números de tarjetas y tokens, respectivamente.

Los números de tarjetas bancarias cuentan con entre 12 y 19 dígitos, y se
encuentran normados por el estándar ISO/IEC-7812~\cite{iso_7812}. El último
dígito se trata de un código de verificación calculado mediante el algoritmo de
Luhn; este dígito hace que \textsc{algoritmoDeLuhn($ x $) = 0}. Para poder
diferenciar a los números de tarjeta válidos de los tokens se establece que,
para los tokens, el dígito verificador haga que
\textsc{algoritmoDeLuhn($ x $) = 1}~\cite{doc_sandra}.

% Hay una corrección diciendo que falta una cita en la última frase. La que
% pongo ahorita es del artículo de Sandra: dentro de uno de los dos requisitos
% se establece que los tokens tienen un dígito de verificación que hace que el
% algoritmo de Luhn dé 1. La corrección también se podría referir a que citemos
% en donde dice que las tarjetas deben cumplir con el algoritmo de Luhn, en cuyo
% caso es la cita de arriba (la del iso); o referir a en donde se define el
% algoritmo de Luhn, que también está en el ISO. La patente original de Luhn
% está enfocada a un aespecie de calculadora o hardware (eran los años 50)
% para calcular el dígito.

\subsection{Clasificación del PCI SSC}
\label{sec:clasificacion}

El PCI SSC (\textit{Payment Card Industry Security Standard Council}) establece
en sus guías de tokenización la siguiente clasificación para los algoritmos
tokenizadores~\cite{pci_tokens}:

\begin{itemize}
  \item Métodos reversibles. Aquellos para los cuales es posible obtener el
    número de tarjeta a partir del token.
    \begin{itemize}
      \item Criptográficos. Utilizan un esquema de cifrado simétrico: el número
        de tarjeta y una llave entran al mecanismo de tokenización para obtener
        un token; el token y la misma llave entran al mecanismo de
        detokenización para obtener el número de tarjeta original.
      \item No criptográficos. Ocupan una base de datos para guardar las
        relaciones entre números de tarjetas y tokens; el proceso de
        detokenización simplemente es una consulta a la base de datos.
    \end{itemize}
  \item Métodos irreversibles. Aquellos en los que no es posible obtener el
    número de tarjeta original a partir del token.
    \begin{itemize}
      \item Autenticable. Permiten validar cuando un token dado corresponde a
        un número de tarjeta dado.
      \item No autenticable. No permiten hacer la validación anterior.
    \end{itemize}
\end{itemize}

\subsection{Algoritmos implementados}
\label{sec:implementaciones}

\textbf{FFX y BPS}. Cifrados que preservan el formato. En~\cite{nist_fpe} el
NIST (\textit{National Institute of Standards and Technology}) los estandariza,
denominándolos FF1 y FF3, respectivamente.

% TODO: definir AES-CBC-MAC

FFX (\textit{Format-preserving Feistel-based Encryption}) fue presentado
en~\cite{ffx_1} por Mihir Bellare, Phillip Rogaway y Terence Spies. En su forma
más general, se compone de una serie de parámetros que permiten cifrar cadenas
de cualquier longitud en cualquier alfabeto; los autores también proponen dos
formas más específicas (dos colecciones de parámetros) para alfabetos binarios y
alfabetos decimales: A2 y A10, respectivamente. FFX A10 usa una red Feistel
alternante junto con una adaptación de AES-CBC-MAC (usada como función de ronda)
para lograr preservar el formato.

BPS fue diseñado por Eric Brier, Thomas Peyrin y Jacques Stern~\cite{bps}. Se
conforma de 2 partes: un cifrado interno $BC$ que se encarga de cifrar bloques
de longitud fija; y un modo de operación especial, encargado de extender la
funcionalidad de $BC$ y permitir cifrar cadenas de mayor longitud.

% El cifrado interno utiliza una red Feistel alternante y se define como
% $BC_{F,s,b,w}(X,K,T)$, donde $F$ es un cifrado por bloques con $f$ bits de
% salida; $s$ es la cardinalidad del alfabeto de la cadena a cifrar, $b$ es su
% longitud, $w$ es el número de rondas de la red Feistel, $X$ es la cadena, $K$ es
% una llave acorde al cifrado $F$, y $T$ es un \textit{tweak} de 64 bits. El modo
% de operación de BPS es un variación de CBC, con la diferencia de que usa sumas
% modulares carácter por carácter en lugar de aplicar operaciones \textit{xor},
% además de que no emplea un vector de inicialización.

\textbf{TKR}. En~\cite{doc_sandra} se analiza formalmente el problema de la
generación de tokens y se propone un algoritmo que no está basado en cifrados
que preservan el formato. Hasta antes de la publicación de este documento, los
únicos métodos para generar tokens cuya seguridad estaba formalmente demostrada
eran los basados en cifrados que preservan el formato.

El algoritmo propuesto usa un cifrado por bloques para generar tokens
pseudoaleatorios y almacena en una base de datos la relación original de estos
con los números de tarjetas. El proceso de detokenización es simplemente una
consulta sobre la base de datos. El modo de generación de tokens
pseudoaleatorios es similar a la opración de un DRBG: como semilla se mantiene
un contador interno que es operado a lo largo de las distintas llamadas como el
modo de operación de contador; los bits generados pasan por una etapa de
interpretación que produce tokens válidos.

\textbf{AHR}. En 2017, Longo, Aragona y Sala~\cite{aragona} propusieron un
algoritmo que denominaron \textit{híbrido reversible} que está basado en un
cifrador por bloques y utiliza una base de datos para almacenar las relaciones
entre número de tarjeta y token.

Las entradas del algoritmo son la parte del número de tarjeta a cifrar y una
entrada adicional (por ejemplo, la fecha) que permite que se tengan varios
tokens relacionados con la misma tarjeta. Como se desea obtener un token que
tenga el mismo número de dígitos que la tarjeta ingresada, se utiliza un método
llamado \textit{caminata cíclica} para asegurarse de que el texto cifrado
pertenezca al espacio del texto en claro.

\textbf{DRBG}. \textit{Deterministic Random Bit Generator}. Probablemente este
método es el más directo para generar tokens. La idea es producir una cadena
binaria aleatoria con un DRBG e interpretarla para que tenga el formato de un
token. Para este trabajo se hizo la implementación de dos DRBG: uno basado en
SHA (\textit{Secure Hash Algorithm}) y el otro basado en un cifrado por
bloques; ambos definidos en el estándar del NIST 800-90A~\cite{nist_aleatorios}.

El método que utiliza como mecanismo interno a una función \textit{hash}
consiste en ir concatenando de forma consecutiva los valores \textit{hash}
derivados de la semilla e ir incrementando el valor de esta. El método basado en
un cifrador por bloques utiliza el modo de operación CTR, en donde la
semilla juega el papel de vector de inicialización. En ambos casos, la seguridad
se basa en que la semilla sea un valor secreto.

Según la clasificación del PCI (Sección \ref{sec:clasificacion}), FFX y BPS son
algoritmos reversibles criptográficos, ya que al ser cifrados que preservan el
formato, funcionan como esquema de cifrado simétrico. TKR, AHR y DRBG son,
contradictoriamente, reversibles no criptográficos, pues necesitan de una base
de datos para guardar las relaciones entre números de tarjeta y tokens.

%\subimport{/}{tkr}
%\subimport{/}{ffx}
%\subimport{/}{bps}
%\subimport{/}{ahr}
%\subimport{/}{drbg}
